{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd7653d-33a9-4336-8ab2-01465d376be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 02:11:45.456350: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-25 02:11:47.589551: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-25 02:11:48.038813: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-25 02:11:48.278782: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-25 02:11:49.335890: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-25 02:11:51.999372: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading matrices!\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Layer, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateScheduler,\n",
    "    LambdaCallback,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler  # for scaling input and output data\n",
    "from sklearn.preprocessing import RobustScaler  # for scaling input and output data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.interpolate import interp1d, make_interp_spline\n",
    "import argparse\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from classy import Class\n",
    "from train_pybird_emulators.emu_utils import integrated_model\n",
    "from train_pybird_emulators.emu_utils import emu_utils\n",
    "from cosmic_toolbox import logger\n",
    "from train_pybird_emulators.emu_utils.k_arrays import k_emu, k_pybird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b106484-4c2e-4db6-a5be-fdb893250d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_name = \"IRPsloop\"\n",
    "model_name = \"test_ploopl\"\n",
    "ntrain=1000000\n",
    "mono=True\n",
    "quad_hex=False\n",
    "mask_high_k=False\n",
    "quad_alone=False\n",
    "hex_alone=False\n",
    "k_array_length = 77\n",
    "training_data_file = \"/cluster/scratch/areeves/pk_bank_boss_gaussian_cov_fixed_bug2/total_data.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a5d5a16-0620-4664-8beb-05cc74260547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cov shape (231, 231)\n"
     ]
    }
   ],
   "source": [
    "cov = emu_utils.get_default_cov()\n",
    "print(\"cov shape\", cov.shape)\n",
    "flattened_rescale_factor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2c4292d-126e-4f75-b3f7-e5cec7382f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-11-25 02:21:54 train_pybi INF   total number of available training points: 896400 \n",
      "24-11-25 02:21:54 train_pybi INF   Available keys in the file: <KeysViewHDF5 ['D', 'IRPs11', 'IRPsct', 'IRPsloop', 'Ploopl', 'bpk_resum_False', 'bpk_resum_True', 'emu_inputs', 'f', 'kk', 'params', 'pk_lin']> \n",
      "xtrain shape (896400, 82)\n",
      "24-11-25 02:23:34 train_pybi INF   Using monopole data for IRPsloop \n",
      "where are zeros?\n",
      "(array([   0,    1,    2,    3,    4,    5,    6,    7,   77,   78,   79,\n",
      "         80,   81,   82,   83,   84,  154,  155,  156,  157,  158,  159,\n",
      "        160,  161,  231,  232,  233,  234,  235,  236,  237,  238,  308,\n",
      "        309,  310,  311,  312,  313,  314,  315,  385,  386,  387,  388,\n",
      "        389,  390,  391,  392,  462,  463,  464,  465,  466,  467,  468,\n",
      "        469,  539,  540,  541,  542,  543,  544,  545,  546,  616,  617,\n",
      "        618,  619,  620,  621,  622,  623,  693,  694,  695,  696,  697,\n",
      "        698,  699,  700,  770,  771,  772,  773,  774,  775,  776,  777,\n",
      "        847,  848,  849,  850,  851,  852,  853,  854,  924,  925,  926,\n",
      "        927,  928,  929,  930,  931, 1001, 1002, 1003, 1004, 1005, 1006,\n",
      "       1007, 1008, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1155,\n",
      "       1156, 1157, 1158, 1159, 1160, 1161, 1162, 1232, 1233, 1234, 1235,\n",
      "       1236, 1237, 1238, 1239, 1309, 1310, 1311, 1312, 1313, 1314, 1315,\n",
      "       1316, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1463, 1464,\n",
      "       1465, 1466, 1467, 1468, 1469, 1470, 1540, 1541, 1542, 1543, 1544,\n",
      "       1545, 1546, 1547, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624,\n",
      "       1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1771, 1772, 1773,\n",
      "       1774, 1775, 1776, 1777, 1778, 1848, 1849, 1850, 1851, 1852, 1853,\n",
      "       1854, 1855, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 2002,\n",
      "       2003, 2004, 2005, 2006, 2007, 2008, 2009, 2079, 2080, 2081, 2082,\n",
      "       2083, 2084, 2085, 2086, 2156, 2157, 2158, 2159, 2160, 2161, 2162,\n",
      "       2163, 2233, 2234, 2235, 2236, 2237, 2238, 2239, 2240, 2310, 2311,\n",
      "       2312, 2313, 2314, 2315, 2316, 2317, 2387, 2388, 2389, 2390, 2391,\n",
      "       2392, 2393, 2394, 2464, 2465, 2466, 2467, 2468, 2469, 2470, 2471,\n",
      "       2541, 2542, 2543, 2544, 2545, 2546, 2547, 2548, 2618, 2619, 2620,\n",
      "       2621, 2622, 2623, 2624, 2625, 2695, 2696, 2697, 2698, 2699, 2700,\n",
      "       2701, 2702, 2772, 2773, 2774, 2775, 2776, 2777, 2778, 2779, 2849,\n",
      "       2850, 2851, 2852, 2853, 2854, 2855, 2856, 2926, 2927, 2928, 2929,\n",
      "       2930, 2931, 2932, 2933, 3003, 3004, 3005, 3006, 3007, 3008, 3009,\n",
      "       3010, 3080, 3081, 3082, 3083, 3084, 3085, 3086, 3087, 3157, 3158,\n",
      "       3159, 3160, 3161, 3162, 3163, 3164, 3234, 3235, 3236, 3237, 3238,\n",
      "       3239, 3240, 3241, 3311, 3312, 3313, 3314, 3315, 3316, 3317, 3318,\n",
      "       3388, 3389, 3390, 3391, 3392, 3393, 3394, 3395, 3465, 3466, 3467,\n",
      "       3468, 3469, 3470, 3471, 3472, 3542, 3543, 3544, 3545, 3546, 3547,\n",
      "       3548, 3549, 3619, 3620, 3621, 3622, 3623, 3624, 3625, 3626, 3696,\n",
      "       3697, 3698, 3699, 3700, 3701, 3702, 3703, 3773, 3774, 3775, 3776,\n",
      "       3777, 3778, 3779, 3780, 3850, 3851, 3852, 3853, 3854, 3855, 3856,\n",
      "       3857, 3927, 3928, 3929, 3930, 3931, 3932, 3933, 3934, 4004, 4005,\n",
      "       4006, 4007, 4008, 4009, 4010, 4011, 4081, 4082, 4083, 4084, 4085,\n",
      "       4086, 4087, 4088, 4158, 4159, 4160, 4161, 4162, 4163, 4164, 4165,\n",
      "       4235, 4236, 4237, 4238, 4239, 4240, 4241, 4242, 4312, 4313, 4314,\n",
      "       4315, 4316, 4317, 4318, 4319, 4389, 4390, 4391, 4392, 4393, 4394,\n",
      "       4395, 4396, 4466, 4467, 4468, 4469, 4470, 4471, 4472, 4473, 4543,\n",
      "       4544, 4545, 4546, 4547, 4548, 4549, 4550, 4620, 4621, 4622, 4623,\n",
      "       4624, 4625, 4626, 4627, 4697, 4698, 4699, 4700, 4701, 4702, 4703,\n",
      "       4704, 4774, 4775, 4776, 4777, 4778, 4779, 4780, 4781, 4851, 4852,\n",
      "       4853, 4854, 4855, 4856, 4857, 4858, 4928, 4929, 4930, 4931, 4932,\n",
      "       4933, 4934, 4935, 5005, 5006, 5007, 5008, 5009, 5010, 5011, 5012,\n",
      "       5082, 5083, 5084, 5085, 5086, 5087, 5088, 5089, 5159, 5160, 5161,\n",
      "       5162, 5163, 5164, 5165, 5166, 5236, 5237, 5238, 5239, 5240, 5241,\n",
      "       5242, 5243, 5313, 5314, 5315, 5316, 5317, 5318, 5319, 5320, 5390,\n",
      "       5391, 5392, 5393, 5394, 5395, 5396, 5397, 5467, 5468, 5469, 5470,\n",
      "       5471, 5472, 5473, 5474, 5544, 5545, 5546, 5547, 5548, 5549, 5550,\n",
      "       5551, 5621, 5622, 5623, 5624, 5625, 5626, 5627, 5628, 5698, 5699,\n",
      "       5700, 5701, 5702, 5703, 5704, 5705, 5775, 5776, 5777, 5778, 5779,\n",
      "       5780, 5781, 5782, 5852, 5853, 5854, 5855, 5856, 5857, 5858, 5859,\n",
      "       5929, 5930, 5931, 5932, 5933, 5934, 5935, 5936, 6006, 6007, 6008,\n",
      "       6009, 6010, 6011, 6012, 6013, 6083, 6084, 6085, 6086, 6087, 6088,\n",
      "       6089, 6090, 6160, 6161, 6162, 6163, 6164, 6165, 6166, 6167, 6237,\n",
      "       6238, 6239, 6240, 6241, 6242, 6243, 6244, 6314, 6315, 6316, 6317,\n",
      "       6318, 6319, 6320, 6321, 6391, 6392, 6393, 6394, 6395, 6396, 6397,\n",
      "       6398, 6468, 6469, 6470, 6471, 6472, 6473, 6474, 6475, 6545, 6546,\n",
      "       6547, 6548, 6549, 6550, 6551, 6552, 6622, 6623, 6624, 6625, 6626,\n",
      "       6627, 6628, 6629, 6699, 6700, 6701, 6702, 6703, 6704, 6705, 6706,\n",
      "       6776, 6777, 6778, 6779, 6780, 6781, 6782, 6783, 6853, 6854, 6855,\n",
      "       6856, 6857, 6858, 6859, 6860, 6930, 6931, 6932, 6933, 6934, 6935,\n",
      "       6936, 6937, 7007, 7008, 7009, 7010, 7011, 7012, 7013, 7014, 7084,\n",
      "       7085, 7086, 7087, 7088, 7089, 7090, 7091, 7161, 7162, 7163, 7164,\n",
      "       7165, 7166, 7167, 7168, 7238, 7239, 7240, 7241, 7242, 7243, 7244,\n",
      "       7245, 7315, 7316, 7317, 7318, 7319, 7320, 7321, 7322, 7392, 7393,\n",
      "       7394, 7395, 7396, 7397, 7398, 7399, 7469, 7470, 7471, 7472, 7473,\n",
      "       7474, 7475, 7476, 7546, 7547, 7548, 7549, 7550, 7551, 7552, 7553,\n",
      "       7623, 7624, 7625, 7626, 7627, 7628, 7629, 7630, 7700, 7701, 7702,\n",
      "       7703, 7704, 7705, 7706, 7707, 7777, 7778, 7779, 7780, 7781, 7782,\n",
      "       7783, 7784, 7854, 7855, 7856, 7857, 7858, 7859, 7860, 7861, 7931,\n",
      "       7932, 7933, 7934, 7935, 7936, 7937, 7938, 8008, 8009, 8010, 8011,\n",
      "       8012, 8013, 8014, 8015]),)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = emu_utils.get_training_data_from_hdf5(\n",
    "    training_data_file,\n",
    "    piece_name,\n",
    "    ntrain,\n",
    "    mono,\n",
    "    quad_hex,\n",
    "    quad_alone,\n",
    "    hex_alone,\n",
    "    mask_high_k\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc116164-1d76-40b5-9476-baaf9c5eca18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig shape (896400, 82)\n"
     ]
    }
   ],
   "source": [
    "# print(f\"filtering out bad indices for piece {piece_name}\")\n",
    "\n",
    "print(\"orig shape\", x_train.shape)\n",
    "condition_1 = np.any(x_train[:, :-2] > 0, axis=1)\n",
    "condition_2 = x_train[:, -1] < 0\n",
    "condition_3 = x_train[:, -2] < 0\n",
    "bad_inds = np.where(condition_1 | condition_2 | condition_3)[0]\n",
    "\n",
    "# # bad_inds = np.where(condition_1 | condition_2 | condition_3 | condition_4)[0]\n",
    "\n",
    "# #ensure that the gradients in the first 10 knots are not consecutively negative \n",
    "# # New condition: Two consecutive negative gradients in the first 10 positions\n",
    "# # Compute gradients in the first 10 positions\n",
    "gradients_first_5 = np.diff(x_train[:, :6], axis=1)  # Shape: (num_samples, 10)\n",
    "\n",
    "# # # Identify negative gradients\n",
    "negative_gradients = gradients_first_5 < 0  # Shape: (num_samples, 10)\n",
    "condition_4 = np.any(negative_gradients, axis=1)\n",
    "\n",
    "\n",
    "bad_inds = np.where(condition_1 | condition_2 | condition_3 | condition_4)[0]\n",
    "\n",
    "\n",
    "# if piece_name.startswith(\"I\"):\n",
    "#     print(\"training IR piece... going to filter out large gradients\")\n",
    "    # Calculate the absolute gradients along each row\n",
    "gradients = np.abs(np.diff(y_train, axis=1))\n",
    "\n",
    "gradient_threshold = np.quantile(\n",
    "    gradients, 0.9995\n",
    ")  # top 15% of gradients\n",
    "\n",
    "# spikes typically happen around high k\n",
    "spike_positions = np.arange(\n",
    "    k_emu.shape[0] - 1, gradients.shape[1], k_emu.shape[0]\n",
    ")  # Adjust for 0-index and diff output size\n",
    "\n",
    "# Condition to identify rows with gradient spikes at specific positions\n",
    "condition_5= np.any(\n",
    "    gradients[:, spike_positions] > gradient_threshold, axis=1\n",
    ")\n",
    "\n",
    "\n",
    "bad_inds = np.where(\n",
    "    condition_1 | condition_2 | condition_3  |condition_5\n",
    ")[0]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "print(f\"removing {len(bad_inds)} bad indices\")\n",
    "x_train = np.delete(x_train, bad_inds, axis=0)\n",
    "y_train = np.delete(y_train, bad_inds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.where(condition_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a97c2e-0ba0-4389-b60b-1621b0852411",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e48a73-c263-4c57-b3ee-921c22680cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x_train[:,-2], bins=100)\n",
    "plt.xlim(-100,300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b2345-ff3c-423a-b48c-c750e826b609",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(650): \n",
    "    plt.plot(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5687b9-5233-4c7b-9588-ae46e442a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.abs(y_train)==np.amax(np.abs(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf56ec-aff0-4de6-9222-507deee7abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(900): \n",
    "    plt.plot(y_train[i])\n",
    "plt.plot(y_train[np.where(np.abs(y_train)==np.amax(np.abs(y_train)))[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ef6661-73dd-4e26-855e-0fed79949bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa2256b-fa32-4a70-a9a5-215a22f1dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_params= x_train[np.where(np.abs(y_train)==np.amax(np.abs(y_train)))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd5ccad-bee8-479a-8294-346cf4059621",
   "metadata": {},
   "outputs": [],
   "source": [
    "knots = np.load(\"/cluster/work/refregier/alexree/local_packages/train_pybird_emulators/src/train_pybird_emulators/data/knots_data/final_knots_80.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e35231-844c-4452-807d-0c01b4ca0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knots[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3af1d7-103f-4839-a399-c1b42f939706",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(knots, np.exp(max_params[0, :80]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea3f03-489e-43ff-b22b-66f31b5b471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_params[0, -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da699b32-b680-4b66-a8b7-108434292320",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flattened_rescale_factor is not None:\n",
    "    num_patterns = y_train.shape[1] // k_array_length\n",
    "    rescaling_factor = emu_utils.generate_repeating_array(\n",
    "        flattened_rescale_factor, 77, num_patterns // 3\n",
    "    )\n",
    "    if mono:\n",
    "        rescaling_factor = emu_utils.generate_repeating_array(\n",
    "            flattened_rescale_factor, 77, num_patterns\n",
    "        )\n",
    "        rescaling_factor = rescaling_factor[: 35 * 77]\n",
    "    if quad_hex:\n",
    "        rescaling_factor = emu_utils.generate_repeating_array(\n",
    "            flattened_rescale_factor, 77, 35\n",
    "        )\n",
    "        rescaling_factor = rescaling_factor[35 * 77 :]\n",
    "    if not mono and not quad_hex:\n",
    "        rescaling_factor = rescaling_factor\n",
    "    rescaling_factor = np.array(rescaling_factor)\n",
    "else:\n",
    "    rescaling_factor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f73118-4b73-4e73-b775-b9e38eaf3faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(flattened_rescale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683beef9-00a4-4d59-af8c-e119d120bad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(1/rescaling_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc87825-36fc-44a9-8ebe-fca3993e278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there places where all the columns in the data are zero?\n",
    "zero_columns = np.where(np.sum(np.abs(y_train), axis=0) == 0)[0]\n",
    "\n",
    "if zero_columns is not None and zero_columns.shape[0] > 0:\n",
    "    # LOGGER.info(f\"removing zero columns for piece {args.piece_name}\")\n",
    "    # remove and save zero columns indices\n",
    "    np.save(f\"zero_coumns_{piece_name}\", zero_columns)\n",
    "    y_train = np.delete(y_train, zero_columns, axis=1)\n",
    "    if rescaling_factor is not None:\n",
    "        rescaling_factor = np.delete(rescaling_factor, zero_columns, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1a9e86-d601-4753-a290-de32b119527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"using PCA preprocessing\")\n",
    "# npca=512\n",
    "# pca_scaler = StandardScaler().fit(y_train)\n",
    "# pca = PCA(n_components=npca)\n",
    "# # Fit PCA to standard scaled data\n",
    "# normalized_data = pca_scaler.transform(y_train)\n",
    "# pca.fit(normalized_data)\n",
    "# y_train = pca.transform(normalized_data)\n",
    "# rescaling_factor = np.power(\n",
    "#     pca.explained_variance_, -1\n",
    "# )  # default for PCA is to use the explained variance to weight the components\n",
    "# print(f\"explained variance: {np.sum(pca.explained_variance_ratio_)}\")\n",
    "# print(\"using explained variance to weight the components\")\n",
    "# rescaling_factor = np.array(rescaling_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cad0018-06ce-4083-a414-f5c36efe98fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Log prepocessing\")\n",
    "# offset = np.amin(y_train, axis=0)\n",
    "# offset[offset > 0] = 0\n",
    "# y_train = np.log(y_train - 2 * offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97e0d85-73a0-4fba-a667-19276cb08985",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_scaler = StandardScaler().fit(x_train)\n",
    "output_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "keras_model = integrated_model.create_model(\n",
    "    input_dim=x_train.shape[1],\n",
    "    hidden_layers=[256,256,256,256],\n",
    "    output_dim=y_train.shape[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b930858d-9f61-4636-b62f-e3679be2e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and train\n",
    "model = integrated_model.IntegratedModel(\n",
    "    keras_model,\n",
    "    input_scaler=input_scaler,\n",
    "    output_scaler=output_scaler,\n",
    "    offset=None,\n",
    "    log_preprocess=False,\n",
    "    temp_file=f\"saved_models/{model_name}_temp\",\n",
    "    # pca=pca,\n",
    "    # pca_scaler=pca_scaler,\n",
    "    zero_columns=zero_columns,\n",
    "    rescaling_factor=rescaling_factor,\n",
    ")\n",
    "model.train(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=600,\n",
    "    batch_size=2048,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace7d91-0483-4be3-bfdf-4fe6f244d05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427162ce-1840-464a-a25f-06ff2207a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = emu_utils.get_training_data_from_hdf5(\n",
    "    training_data_file,\n",
    "    piece_name,\n",
    "    n_train,\n",
    "    mono,\n",
    "    quad_hex,\n",
    "    quad_alone, \n",
    "    hex_alone,\n",
    "    mask_high_k,\n",
    "    test_data=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3026ea5c-6512-46c5-8356-7673ad45948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8bb4a6-fb23-43b8-a6a9-203c417e03b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"filtering out bad indices for piece {piece_name}\")\n",
    "\n",
    "condition_1 = np.any(x_test[:, :-2] > 0, axis=1)\n",
    "condition_2 = x_test[:, -1] < 0\n",
    "condition_3 = x_test[:, -2] < 0\n",
    "condition_4 = x_test[:, -2] > 20000\n",
    "gradients_first_10 = np.diff(x_test[:, :11], axis=1)  # Shape: (num_samples, 10)\n",
    "\n",
    "# Identify negative gradients\n",
    "negative_gradients = gradients_first_10 < 0  # Shape: (num_samples, 10)\n",
    "\n",
    "# Find two consecutive negative gradients\n",
    "neg_gradients_original = negative_gradients[:, :-1]  # Exclude last element\n",
    "neg_gradients_shifted = negative_gradients[:, 1:]    # Exclude first element\n",
    "\n",
    "consecutive_negatives = neg_gradients_original & neg_gradients_shifted  # Shape: (num_samples, 9)\n",
    "\n",
    "# Condition 6: Samples with two consecutive negative gradients in first 10 positions\n",
    "condition_5 = np.any(negative_gradients, axis=1)\n",
    "\n",
    "bad_inds = np.where(condition_1 | condition_2 | condition_3 | condition_4 | condition_5)[0]\n",
    "\n",
    "\n",
    "\n",
    "if piece_name.startswith(\"I\"):\n",
    "    print(\"training IR piece... going to filter out large gradients\")\n",
    "    # Calculate the absolute gradients along each row\n",
    "    gradients = np.abs(np.diff(y_test, axis=1))\n",
    "    \n",
    "    gradient_threshold = np.quantile(\n",
    "        gradients, 0.80\n",
    "    )  # top 15% of gradients\n",
    "    \n",
    "    # spikes typically happen around high k\n",
    "    spike_positions = np.arange(\n",
    "        k_emu.shape[0] - 1, gradients.shape[1], k_emu.shape[0]\n",
    "    )  # Adjust for 0-index and diff output size\n",
    "    \n",
    "    # Condition to identify rows with gradient spikes at specific positions\n",
    "    condition_5= np.any(\n",
    "        gradients[:, spike_positions] > gradient_threshold, axis=1\n",
    "    )\n",
    "    \n",
    "    \n",
    "    bad_inds = np.where(\n",
    "        condition_1 | condition_2 | condition_3 | condition_5 \n",
    "    )[0]\n",
    "\n",
    "print(f\"removing {len(bad_inds)} bad indices\")\n",
    "x_test = np.delete(x_test, bad_inds, axis=0)\n",
    "y_test = np.delete(y_test, bad_inds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dde8e28-c3a4-49a8-9799-7218f6958393",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"test_models/{model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f33d1c-b849-41ff-a8a2-b5c575d4d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = integrated_model.IntegratedModel(None,None,None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029af248-c952-430b-9e88-6848b3e43b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.restore(f\"test_models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bacb2a5-c296-47bf-bd86-255e1911e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"/cluster/work/refregier/alexree/local_packages/train_pybird_emulators/src/train_pybird_emulators/notebooks/test_models/test_ploopl.pkl\", \"rb\") as f:\n",
    "#     attributes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef58398-c0d2-47f9-a6bd-6a6e335c25de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.log_preprocess = False \n",
    "predicted_testing_spectra = test_model.predict(x_test)\n",
    "# predicted_testing_spectra = model.predict(x_test)\n",
    "\n",
    "testing_spectra = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35247a1-64e2-485d-b920-26dbfa00411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=5, figsize=(16,20))\n",
    "for j in range(5):\n",
    "    for i in range(5):\n",
    "        pred = predicted_testing_spectra[i+j*3]\n",
    "        true = testing_spectra[i+j*3]\n",
    "        ell_range = np.arange(true.shape[0])\n",
    "        ax[j, i].plot(ell_range, true, 'blue', label = 'Original')\n",
    "        ax[j, i].plot(ell_range, pred, 'red', label = 'NN reconstructed', linestyle='--')\n",
    "        ax[j, i].set_xlabel('$\\ell$', fontsize='x-large')\n",
    "        ax[j, i].set_ylabel('$\\\\frac{[\\ell(\\ell+1)]^2}{2 \\pi} C_\\ell$', fontsize='x-large')\n",
    "        ax[j, i].legend(fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed156e9-78e2-46a0-b056-2f8f81aec8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1-np.median(np.abs((testing_spectra[:, ~zero_columns]-predicted_testing_spectra[:, ~zero_columns])/testing_spectra[:, ~zero_columns])))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ee2447-75dd-48b2-86da-aae962458b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pybird_emu_train",
   "language": "python",
   "name": "pybird_emu_train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
